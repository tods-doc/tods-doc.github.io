
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>tods.detection_algorithm &#8212; TODS 0.0.1 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script src="_static/design-tabs.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="tods.reinforcement" href="tods.reinforcement.html" />
    <link rel="prev" title="tods.feature_analysis" href="tods.feature_analysis.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/tods_menu_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">TODS 0.0.1 documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Documentation:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="overview.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="getting_started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="PythonPathCheatSheet.html">
   Python Path Cheat Sheet
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  API Documents:
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="tods.data_processing.html">
   tods.data_processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tods.timeseries_processing.html">
   tods.timeseries_processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tods.feature_analysis.html">
   tods.feature_analysis
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   tods.detection_algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tods.reinforcement.html">
   tods.reinforcement
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/datamllab/tods"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/tods.detection_algorithm.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#autoregodetect">
   AutoRegODetect
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dagmm">
   DAGMM
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deeplog">
   DeepLog
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ensemble">
   Ensemble
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kdiscordodetect">
   KDiscordODetect
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lstmodetect">
   LSTMODetect
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matrixprofile">
   MatrixProfile
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pcaodetect">
   PCAODetect
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodabod">
   PyodABOD
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodae">
   PyodAE
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodcblof">
   PyodCBLOF
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodcof">
   PyodCOF
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodhbos">
   PyodHBOS
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodisolationforest">
   PyodIsolationForest
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodknn">
   PyodKNN
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodloda">
   PyodLODA
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodlof">
   PyodLOF
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodmogaal">
   PyodMoGaal
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodocsvm">
   PyodOCSVM
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodsod">
   PyodSOD
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodsogaal">
   PyodSoGaal
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodvae">
   PyodVAE
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#systemwisedetection">
   SystemWiseDetection
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#telemanom">
   Telemanom
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#uodbaseprimitive">
   UODBasePrimitive
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reference">
   Reference
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>tods.detection_algorithm</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#autoregodetect">
   AutoRegODetect
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dagmm">
   DAGMM
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deeplog">
   DeepLog
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ensemble">
   Ensemble
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kdiscordodetect">
   KDiscordODetect
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lstmodetect">
   LSTMODetect
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matrixprofile">
   MatrixProfile
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pcaodetect">
   PCAODetect
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodabod">
   PyodABOD
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodae">
   PyodAE
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodcblof">
   PyodCBLOF
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodcof">
   PyodCOF
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodhbos">
   PyodHBOS
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodisolationforest">
   PyodIsolationForest
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodknn">
   PyodKNN
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodloda">
   PyodLODA
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodlof">
   PyodLOF
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodmogaal">
   PyodMoGaal
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodocsvm">
   PyodOCSVM
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodsod">
   PyodSOD
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodsogaal">
   PyodSoGaal
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pyodvae">
   PyodVAE
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#systemwisedetection">
   SystemWiseDetection
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#telemanom">
   Telemanom
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#uodbaseprimitive">
   UODBasePrimitive
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reference">
   Reference
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="tods-detection-algorithm">
<h1>tods.detection_algorithm<a class="headerlink" href="#tods-detection-algorithm" title="Permalink to this headline">#</a></h1>
<section id="autoregodetect">
<span id="tods-detection-algorithm-autoregodetect"></span><h2>AutoRegODetect<a class="headerlink" href="#autoregodetect" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.AutoRegODetect.AutoRegODetectorPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.AutoRegODetect.</span></span><span class="sig-name descname"><span class="pre">AutoRegODetectorPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.AutoRegODetect.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/AutoRegODetect.py#L88"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.AutoRegODetect.AutoRegODetectorPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl>
<dt>Autoregressive models use linear regression to calculate a sample’s</dt><dd><p>deviance from the predicted value, which is then used as its
outlier scores. This model is for multivariate time series.
This model handles multivariate time series by various combination
approaches. See AutoRegOD for univarite data.</p>
<p>See <span id="id1">Aggarwal [<a class="reference internal" href="#id29" title="Charu C Aggarwal. Outlier analysis. In Data mining, 75–79. Springer, 2015.">Agg15</a>]</span> for details.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>window_size</strong> (<em>int</em>) – The moving window size.</p></li>
<li><p><strong>step_size</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The displacement for moving window.</p></li>
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. When fitting this is used
to define the threshold on the decision function.</p></li>
<li><p><strong>method</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>default='average'</em><em>)</em>) – Combination method: {‘average’, ‘maximization’,
‘median’}. Pass in weights of detector for weighted version.</p></li>
<li><p><strong>weights</strong> (<em>numpy array of shape</em><em> (</em><em>1</em><em>, </em><em>n_dimensions</em><em>)</em>) – Score weight by dimensions. (default=[1,1,…,1])</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id67"><span class="problematic" id="id68">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</p>
</dd>
<dt><a href="#id69"><span class="problematic" id="id70">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="dagmm">
<span id="tods-detection-algorithm-dagmm"></span><h2>DAGMM<a class="headerlink" href="#dagmm" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.DAGMM.DAGMMPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.DAGMM.</span></span><span class="sig-name descname"><span class="pre">DAGMMPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.DAGMM.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/DAGMM.py#L99"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.DAGMM.DAGMMPrimitive" title="Permalink to this definition">#</a></dt>
<dd><blockquote>
<div><p>Deep Autoencoding Gaussian Mixture Model</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>comp_hiddens</strong> (<em>List</em><em>(</em><em>default=</em><em>[</em><em>16</em><em>,</em><em>8</em><em>,</em><em>1</em><em>]</em><em>)</em>) – Sizes of hidden layers of compression network.’</p></li>
<li><p><strong>est_hiddens</strong> (<em>List</em><em>(</em><em>default=</em><em>[</em><em>8</em><em>,</em><em>4</em><em>]</em><em>)</em>) – Sizes of hidden layers of estimation network.</p></li>
<li><p><strong>est_dropout_ratio</strong> (<em>float</em><em>(</em><em>default=0.25</em><em>)</em>) – Dropout rate of estimation network</p></li>
<li><p><strong>minibatch_size</strong> (<em>int</em><em>(</em><em>default=3</em><em>)</em>) – Mini Batch size</p></li>
<li><p><strong>epoch_size</strong> (<em>int</em><em>(</em><em>default=100</em><em>)</em>) – Epoch</p></li>
<li><p><strong>int</strong><strong>(</strong><strong>default=0</strong><strong>)</strong> (<em>rand_seed</em>) – (optional )random seed used when fit() is called</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em>(</em><em>default=0.0001</em><em>)</em>) – learning rate</p></li>
<li><p><strong>lambda1</strong> (<em>float</em><em>(</em><em>default=0.1</em><em>)</em>) – a parameter of loss function (for energy term)</p></li>
<li><p><strong>lambda2</strong> (<em>float</em><em>(</em><em>default=0.1</em><em>)</em>) – a parameter of loss function</p></li>
<li><p><strong>normalize</strong> (<em>bool</em><em>(</em><em>default=True</em><em>)</em>) – Specify whether input data need to be normalized.</p></li>
<li><p><strong>contamination</strong> (<em>float</em><em>(</em><em>lower=0.</em><em>,</em><em>upper=0.5</em><em>,</em><em>default=0.1</em><em>)</em>) – the amount of contamination of the data set, i.e.the proportion of outliers in the data set. Used when fitting to define the threshold on the decision function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="deeplog">
<span id="tods-detection-algorithm-deeplog"></span><h2>DeepLog<a class="headerlink" href="#deeplog" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.DeepLog.DeepLogPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.DeepLog.</span></span><span class="sig-name descname"><span class="pre">DeepLogPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.DeepLog.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/DeepLog.py#L152"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.DeepLog.DeepLogPrimitive" title="Permalink to this definition">#</a></dt>
<dd><p>A primitive that uses DeepLog for outlier detection</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em><em>(</em><em>default=64</em><em>)</em>) – hidden state dimension</p></li>
<li><p><strong>loss</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>None</em><em>]</em><em>(</em><em>default='mean_squared_error'</em><em>)</em>) – loss function</p></li>
<li><p><strong>optimizer</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>None</em><em>]</em><em>(</em><em>default='Adam'</em><em>)</em>) – Optimizer</p></li>
<li><p><strong>epochs</strong> (<em>int</em><em>(</em><em>default=10</em><em>)</em>) – Epoch</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>(</em><em>default=32</em><em>)</em>) – Batch size</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em><em>(</em><em>default=0.2</em><em>)</em>) – Dropout rate</p></li>
<li><p><strong>l2_regularizer</strong> (<em>float</em><em>(</em><em>default=0.1</em><em>)</em>) – l2 regularizer</p></li>
<li><p><strong>validation_size</strong> (<em>float</em><em>(</em><em>default=0.1</em><em>)</em>) – validation size</p></li>
<li><p><strong>window_size</strong> (<em>int</em><em>(</em><em>default=1</em><em>)</em>) – window size”</p></li>
<li><p><strong>features</strong> (<em>int</em><em>(</em><em>default=1</em><em>)</em>) – Number of features in Input</p></li>
<li><p><strong>stacked_layers</strong> (<em>int</em><em>(</em><em>default=1</em><em>)</em>) – Number of LSTM layers between input layer and Final Dense Layer</p></li>
<li><p><strong>preprocessing</strong> (<em>Bool</em><em>(</em><em>default=True</em><em>)</em>) – Whether to Preprosses the data</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>(</em><em>default=1</em><em>)</em>) – verbose</p></li>
<li><p><strong>contamination</strong> (<em>float</em><em>(</em><em>lower=0.</em><em>,</em><em>upper=0.5</em><em>,</em><em>default=0.1</em><em>)</em>) – the amount of contamination of the data set, i.e.the proportion of outliers in the data set. Used when fitting to define the threshold on the decision function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="ensemble">
<span id="tods-detection-algorithm-ensemble"></span><h2>Ensemble<a class="headerlink" href="#ensemble" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.Ensemble.EnsemblePrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.Ensemble.</span></span><span class="sig-name descname"><span class="pre">EnsemblePrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.Ensemble.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/Ensemble.py#L112"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.Ensemble.EnsemblePrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Ensemble method</dt><dd><p>Calculate the Maximum/Minimum/Average and  Majority Voting for the detection algorithm based on the threshold set for the score</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>endog</strong> (<em>int</em><em>(</em><em>lower = 2</em><em>,</em><em>upper = None</em><em>,</em><em>default = 3</em><em>)</em>) – Array like time series.</p></li>
<li><p><strong>threshold</strong> (<em>float</em><em>(</em><em>lower = 0</em><em>,</em><em>upper = 1</em><em>,</em><em>default = 0.5</em><em>)</em>) – </p></li>
<li><p><strong>norm</strong> (<em>str</em><em>(</em><em>default='l2'</em><em>,</em><em>values=</em><em>[</em><em>'l1'</em><em>, </em><em>'l2'</em><em>, </em><em>'max'</em><em>]</em><em>)</em>) – The norm to use to normalize each non zero sample.</p></li>
<li><p><strong>use_columns</strong> (<em>Set</em>) – A set of column indices to force primitive to operate on. If any specified column cannot be parsed, it is skipped.</p></li>
<li><p><strong>exclude_columns</strong> (<em>Set</em>) – A set of column indices to not operate on. Applicable only if “use_columns” is not provided.</p></li>
<li><p><strong>return_result</strong> (<em>Enumeration</em>) – Should parsed columns be appended, should they replace original columns, or should only parsed columns be returned? This hyperparam is ignored if use_semantic_types is set to false.</p></li>
<li><p><strong>use_semantic_types</strong> (<em>Bool</em>) – Controls whether semantic_types metadata will be used for filtering columns in input dataframe. Setting this to false makes the code ignore return_result and will produce only the output dataframe</p></li>
<li><p><strong>add_index_columns</strong> (<em>Bool</em>) – Also include primary index columns if input data has them. Applicable only if “return_result” is set to “new”.</p></li>
<li><p><strong>error_on_no_input</strong> (<em>Bool</em>) – Throw an exception if no input column is selected/provided. Defaults to true to behave like sklearn. To prevent pipelines from breaking set this to False.</p></li>
<li><p><strong>return_semantic_type</strong> (<em>Enumeration</em><em>[</em><em>str</em><em>]</em>) – Decides what semantic type to attach to generated attributes</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="kdiscordodetect">
<span id="tods-detection-algorithm-kdiscordodetect"></span><h2>KDiscordODetect<a class="headerlink" href="#kdiscordodetect" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.KDiscordODetect.KDiscordODetectorPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.KDiscordODetect.</span></span><span class="sig-name descname"><span class="pre">KDiscordODetectorPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.KDiscordODetect.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/KDiscordODetect.py#L128"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.KDiscordODetect.KDiscordODetectorPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl>
<dt>KDiscord first split multivariate time series into</dt><dd><p>subsequences (matrices), and it use kNN outlier detection based on PyOD.
For an observation, its distance to its kth nearest neighbor could be
viewed as the outlying score. It could be viewed as a way to measure
the density. See <span id="id2">[<a class="reference internal" href="#id24" title="Fabrizio Angiulli and Clara Pizzuti. Fast outlier detection in high dimensional spaces. In European Conference on Principles of Data Mining and Knowledge Discovery, 15–27. Springer, 2002.">AP02</a>, <a class="reference internal" href="#id23" title="Sridhar Ramaswamy, Rajeev Rastogi, and Kyuseok Shim. Efficient algorithms for mining outliers from large data sets. In ACM Sigmod Record, volume 29, 427–438. ACM, 2000.">RRS00</a>]</span> for
details.</p>
<p>See <span id="id3">[<a class="reference internal" href="#id29" title="Charu C Aggarwal. Outlier analysis. In Data mining, 75–79. Springer, 2015.">Agg15</a>]</span> for details.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>window_size</strong> (<em>int</em>) – The moving window size.</p></li>
<li><p><strong>step_size</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The displacement for moving window.</p></li>
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</p></li>
<li><p><strong>n_neighbors</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default = 5</em><em>)</em>) – Number of neighbors to use by default for k neighbors queries.</p></li>
<li><p><strong>method</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>default='largest'</em><em>)</em>) – <p>{‘largest’, ‘mean’, ‘median’}</p>
<ul>
<li><p>’largest’: use the distance to the kth neighbor as the outlier score</p></li>
<li><p>’mean’: use the average of all k neighbors as the outlier score</p></li>
<li><p>’median’: use the median of the distance to k neighbors as the outlier score</p></li>
</ul>
</p></li>
<li><p><strong>radius</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default = 1.0</em><em>)</em>) – Range of parameter space to use by default for <cite>radius_neighbors</cite>
queries.</p></li>
<li><p><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>optional</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<ul>
<li><p>’ball_tree’ will use BallTree</p></li>
<li><p>’kd_tree’ will use KDTree</p></li>
<li><p>’brute’ will use a brute-force search.</p></li>
<li><p>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> method.</p></li>
</ul>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 0.74: </span><code class="docutils literal notranslate"><span class="pre">algorithm</span></code> is deprecated in PyOD 0.7.4 and will not be
possible in 0.7.6. It has to use BallTree for consistency.</p>
</div>
</p></li>
<li><p><strong>leaf_size</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default = 30</em><em>)</em>) – Leaf size passed to BallTree. This can affect the
speed of the construction and query, as well as the memory
required to store the tree.  The optimal value depends on the
nature of the problem.</p></li>
<li><p><strong>metric</strong> (<em>string</em><em> or </em><em>callable</em><em>, </em><em>default 'minkowski'</em>) – <p>metric to use for distance computation. Any metric from scikit-learn
or scipy.spatial.distance can be used.</p>
<p>If metric is a callable function, it is called on each
pair of instances (rows) and the resulting value recorded. The callable
should take two arrays as input and return one value indicating the
distance between them. This works for Scipy’s metrics, but is less
efficient than passing the metric name as a string.</p>
<p>Distance matrices are not supported.</p>
<p>Valid values for metric are:</p>
<ul>
<li><p>from scikit-learn: [‘cityblock’, ‘cosine’, ‘euclidean’, ‘l1’, ‘l2’,
‘manhattan’]</p></li>
<li><p>from scipy.spatial.distance: [‘braycurtis’, ‘canberra’, ‘chebyshev’,
‘correlation’, ‘dice’, ‘hamming’, ‘jaccard’, ‘kulsinski’,
‘mahalanobis’, ‘matching’, ‘minkowski’, ‘rogerstanimoto’,
‘russellrao’, ‘seuclidean’, ‘sokalmichener’, ‘sokalsneath’,
‘sqeuclidean’, ‘yule’]</p></li>
</ul>
<p>See the documentation for scipy.spatial.distance for details on these
metrics.</p>
</p></li>
<li><p><strong>p</strong> (<em>integer</em><em>, </em><em>optional</em><em> (</em><em>default = 2</em><em>)</em>) – Parameter for the Minkowski metric from
sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is
equivalent to using manhattan_distance (l1), and euclidean_distance
(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.
See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances">http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances</a></p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Additional keyword arguments for the metric function.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id71"><span class="problematic" id="id72">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</p>
</dd>
<dt><a href="#id73"><span class="problematic" id="id74">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id75"><span class="problematic" id="id76">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="lstmodetect">
<span id="tods-detection-algorithm-lstmodetect"></span><h2>LSTMODetect<a class="headerlink" href="#lstmodetect" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.LSTMODetect.LSTMODetectorPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.LSTMODetect.</span></span><span class="sig-name descname"><span class="pre">LSTMODetectorPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.LSTMODetect.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/LSTMODetect.py#L164"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.LSTMODetect.LSTMODetectorPrimitive" title="Permalink to this definition">#</a></dt>
<dd><p>A base class for primitives which have to be fitted before they can start
producing (useful) outputs from inputs, but they are fitted only on input data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>window_size</strong> (<em>int</em>) – The moving window size.</p></li>
<li><p><strong>step_size</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The displacement for moving window.</p></li>
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. When fitting this is used
to define the threshold on the decision function.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id77"><span class="problematic" id="id78">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</p>
</dd>
<dt><a href="#id79"><span class="problematic" id="id80">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="matrixprofile">
<span id="tods-detection-algorithm-matrixprofile"></span><h2>MatrixProfile<a class="headerlink" href="#matrixprofile" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.MatrixProfile.MatrixProfilePrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.MatrixProfile.</span></span><span class="sig-name descname"><span class="pre">MatrixProfilePrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.MatrixProfile.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/MatrixProfile.py#L186"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.MatrixProfile.MatrixProfilePrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>A primitive that performs matrix profile on a DataFrame using Stumpy package</dt><dd><p>Stumpy documentation: <a class="reference external" href="https://stumpy.readthedocs.io/en/latest/index.html">https://stumpy.readthedocs.io/en/latest/index.html</a></p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>T_A</strong> (<em>ndarray</em>) – The time series or sequence for which to compute the matrix profile</p></li>
<li><p><strong>m</strong> (<em>int</em>) – Window size</p></li>
<li><p><strong>T_B</strong> (<em>ndarray</em>) – The time series or sequence that contain your query subsequences
of interest. Default is <cite>None</cite> which corresponds to a self-join.</p></li>
<li><p><strong>ignore_trivial</strong> (<em>bool</em>) – Set to <cite>True</cite> if this is a self-join. Otherwise, for AB-join, set this
to <cite>False</cite>. Default is <cite>True</cite>.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Returns<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt>out<span class="classifier">ndarray</span></dt><dd><p class="sd-card-text">The first column consists of the matrix profile, the second column
consists of the matrix profile indices, the third column consists of
the left matrix profile indices, and the fourth column consists of
the right matrix profile indices.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pcaodetect">
<span id="tods-detection-algorithm-pcaodetect"></span><h2>PCAODetect<a class="headerlink" href="#pcaodetect" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PCAODetect.PCAODetectorPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PCAODetect.</span></span><span class="sig-name descname"><span class="pre">PCAODetectorPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PCAODetect.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PCAODetect.py#L151"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PCAODetect.PCAODetectorPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>PCA-based outlier detection with both univariate and multivariate</dt><dd><p>time series data. TS data will be first transformed to tabular format.
For univariate data, it will be in shape of [valid_length, window_size].
for multivariate data with d sequences, it will be in the shape of
[valid_length, window_size].</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>window_size</strong> (<em>int</em>) – The moving window size.</p></li>
<li><p><strong>step_size</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The displacement for moving window.</p></li>
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</p></li>
<li><p><strong>n_components</strong> (<em>int</em><em>, </em><em>float</em><em>, </em><em>None</em><em> or </em><em>string</em>) – <p>Number of components to keep. It should be smaller than the window_size.
if n_components is not set all components are kept:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_components</span> <span class="o">==</span> <span class="nb">min</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
</pre></div>
</div>
<p>if n_components == ‘mle’ and svd_solver == ‘full’, Minka’s MLE is used
to guess the dimension
if <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;</span> <span class="pre">n_components</span> <span class="pre">&lt;</span> <span class="pre">1</span></code> and svd_solver == ‘full’, select the number
of components such that the amount of variance that needs to be
explained is greater than the percentage specified by n_components
n_components cannot be equal to n_features for svd_solver == ‘arpack’.</p>
</p></li>
<li><p><strong>n_selected_components</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Number of selected principal components
for calculating the outlier scores. It is not necessarily equal to
the total number of the principal components. If not set, use
all principal components.</p></li>
<li><p><strong>whiten</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default False</em><em>)</em>) – <p>When True (False by default) the <cite>components_</cite> vectors are multiplied
by the square root of n_samples and then divided by the singular values
to ensure uncorrelated outputs with unit component-wise variances.</p>
<p>Whitening will remove some information from the transformed signal
(the relative variance scales of the components) but can sometime
improve the predictive accuracy of the downstream estimators by
making their data respect some hard-wired assumptions.</p>
</p></li>
<li><p><strong>svd_solver</strong> (<em>string {'auto'</em><em>, </em><em>'full'</em><em>, </em><em>'arpack'</em><em>, </em><em>'randomized'}</em>) – <ul>
<li><dl class="simple">
<dt>auto :</dt><dd><p>the solver is selected by a default policy based on <cite>X.shape</cite> and
<cite>n_components</cite>: if the input data is larger than 500x500 and the
number of components to extract is lower than 80% of the smallest
dimension of the data, then the more efficient ‘randomized’
method is enabled. Otherwise the exact full SVD is computed and
optionally truncated afterwards.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>full :</dt><dd><p>run exact full SVD calling the standard LAPACK solver via
<cite>scipy.linalg.svd</cite> and select the components by postprocessing</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>arpack :</dt><dd><p>run SVD truncated to n_components calling ARPACK solver via
<cite>scipy.sparse.linalg.svds</cite>. It requires strictly
0 &lt; n_components &lt; X.shape[1]</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>randomized :</dt><dd><p>run randomized SVD by the method of Halko et al.</p>
</dd>
</dl>
</li>
</ul>
</p></li>
<li><p><strong>tol</strong> (<em>float &gt;= 0</em><em>, </em><em>optional</em><em> (</em><em>default .0</em><em>)</em>) – Tolerance for singular values computed by svd_solver == ‘arpack’.</p></li>
<li><p><strong>iterated_power</strong> (<em>int &gt;= 0</em><em>, or </em><em>'auto'</em><em>, </em><em>(</em><em>default 'auto'</em><em>)</em>) – Number of iterations for the power method computed by
svd_solver == ‘randomized’.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default None</em><em>)</em>) – If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>. Used when <code class="docutils literal notranslate"><span class="pre">svd_solver</span></code> == ‘arpack’ or ‘randomized’.</p></li>
<li><p><strong>weighted</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, the eigenvalues are used in score computation.
The eigenvectors with small eigenvalues comes with more importance
in outlier score calculation.</p></li>
<li><p><strong>standardization</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, perform standardization first to convert
data to zero mean and unit variance.
See <a class="reference external" href="http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html">http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html</a></p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id81"><span class="problematic" id="id82">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</p>
</dd>
<dt><a href="#id83"><span class="problematic" id="id84">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id85"><span class="problematic" id="id86">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pyodabod">
<span id="tods-detection-algorithm-pyodabod"></span><h2>PyodABOD<a class="headerlink" href="#pyodabod" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PyodABOD.ABODPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PyodABOD.</span></span><span class="sig-name descname"><span class="pre">ABODPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PyodABOD.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PyodABOD.py#L68"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PyodABOD.ABODPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl>
<dt>ABOD class for Angle-base Outlier Detection.</dt><dd><p>For an observation, the variance of its weighted cosine scores to all
neighbors could be viewed as the outlying score.
See <span id="id4">[<a class="reference internal" href="#id25" title="Hans-Peter Kriegel, Arthur Zimek, and others. Angle-based outlier detection in high-dimensional data. In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, 444–452. ACM, 2008.">KZ+08</a>]</span> for details.</p>
<p>Two versions of ABOD are supported:</p>
<ul class="simple">
<li><p>Fast ABOD: use k nearest neighbors to approximate.</p></li>
<li><p>Original ABOD: consider all training points with high time complexity at
O(n^3).</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</p></li>
<li><p><strong>n_neighbors</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – Number of neighbors to use by default for k neighbors queries.</p></li>
<li><p><strong>method</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>default='fast'</em><em>)</em>) – <p>Valid values for metric are:</p>
<ul>
<li><p>’fast’: fast ABOD. Only consider n_neighbors of training points</p></li>
<li><p>’default’: original ABOD with all training points, which could be
slow</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id87"><span class="problematic" id="id88">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</p>
</dd>
<dt><a href="#id89"><span class="problematic" id="id90">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id91"><span class="problematic" id="id92">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pyodae">
<span id="tods-detection-algorithm-pyodae"></span><h2>PyodAE<a class="headerlink" href="#pyodae" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PyodAE.AutoEncoderPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PyodAE.</span></span><span class="sig-name descname"><span class="pre">AutoEncoderPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PyodAE.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PyodAE.py#L172"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PyodAE.AutoEncoderPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Auto Encoder (AE) is a type of neural networks for learning useful data</dt><dd><p>representations unsupervisedly. Similar to PCA, AE could be used to
detect outlying objects in the data by calculating the reconstruction
errors. See <span id="id5">[<a class="reference internal" href="#id29" title="Charu C Aggarwal. Outlier analysis. In Data mining, 75–79. Springer, 2015.">Agg15</a>]</span> Chapter 3 for details.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_neurons</strong> (<em>list</em><em>, </em><em>optional</em><em> (</em><em>default=</em><em>[</em><em>4</em><em>,</em><em>2</em><em>,</em><em>4</em><em>]</em><em>)</em>) – The number of neurons per hidden layers.</p></li>
<li><p><strong>hidden_activation</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>default='relu'</em><em>)</em>) – Activation function to use for hidden layers.
All hidden layers are forced to use the same type of activation.
See <a class="reference external" href="https://keras.io/activations/">https://keras.io/activations/</a></p></li>
<li><p><strong>output_activation</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>default='sigmoid'</em><em>)</em>) – Activation function to use for output layer.
See <a class="reference external" href="https://keras.io/activations/">https://keras.io/activations/</a></p></li>
<li><p><strong>loss</strong> (<em>str</em><em> or </em><em>obj</em><em>, </em><em>optional</em><em> (</em><em>default=keras.losses.mean_squared_error</em><em>)</em>) – String (name of objective function) or objective function.
See <a class="reference external" href="https://keras.io/losses/">https://keras.io/losses/</a></p></li>
<li><p><strong>optimizer</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>default='adam'</em><em>)</em>) – String (name of optimizer) or optimizer instance.
See <a class="reference external" href="https://keras.io/optimizers/">https://keras.io/optimizers/</a></p></li>
<li><p><strong>epochs</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=100</em><em>)</em>) – Number of epochs to train the model.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=32</em><em>)</em>) – Number of samples per gradient update.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.2</em><em>)</em>) – The dropout to be used across all layers.</p></li>
<li><p><strong>l2_regularizer</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The regularization strength of activity_regularizer
applied on each layer. By default, l2 regularizer is used. See
<a class="reference external" href="https://keras.io/regularizers/">https://keras.io/regularizers/</a></p></li>
<li><p><strong>validation_size</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The percentage of data to be used for validation.</p></li>
<li><p><strong>preprocessing</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, apply standardization on the data.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – Verbosity mode.
- 0 = silent
- 1 = progress bar
- 2 = one line per epoch.
For verbosity &gt;= 1, model summary may be printed.</p></li>
<li><p><strong>random_state</strong> (<em>random_state: int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – (default=None)
If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <cite>np.random</cite>.</p></li>
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. When fitting this is used
to define the threshold on the decision function.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id93"><span class="problematic" id="id94">encoding_dim_</span></a><span class="classifier">int</span></dt><dd><p class="sd-card-text">The number of neurons in the encoding layer.</p>
</dd>
<dt><a href="#id95"><span class="problematic" id="id96">compression_rate_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The ratio between the original feature and
the number of neurons in the encoding layer.</p>
</dd>
<dt><a href="#id97"><span class="problematic" id="id98">model_</span></a><span class="classifier">Keras Object</span></dt><dd><p class="sd-card-text">The underlying AutoEncoder in Keras.</p>
</dd>
<dt><a href="#id99"><span class="problematic" id="id100">history_</span></a>: Keras Object</dt><dd><p class="sd-card-text">The AutoEncoder training history.</p>
</dd>
<dt><a href="#id101"><span class="problematic" id="id102">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</p>
</dd>
<dt><a href="#id103"><span class="problematic" id="id104">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id105"><span class="problematic" id="id106">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pyodcblof">
<span id="tods-detection-algorithm-pyodcblof"></span><h2>PyodCBLOF<a class="headerlink" href="#pyodcblof" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PyodCBLOF.CBLOFPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PyodCBLOF.</span></span><span class="sig-name descname"><span class="pre">CBLOFPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PyodCBLOF.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PyodCBLOF.py#L116"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PyodCBLOF.CBLOFPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>The CBLOF operator calculates the outlier score based on cluster-based</dt><dd><p>local outlier factor.
CBLOF takes as an input the data set and the cluster model that was
generated by a clustering algorithm. It classifies the clusters into small
clusters and large clusters using the parameters alpha and beta.
The anomaly score is then calculated based on the size of the cluster the
point belongs to as well as the distance to the nearest large cluster.
Use weighting for outlier factor based on the sizes of the clusters as
proposed in the original publication. Since this might lead to unexpected
behavior (outliers close to small clusters are not found), it is disabled
by default.Outliers scores are solely computed based on their distance to
the closest large cluster center.
By default, kMeans is used for clustering algorithm instead of
Squeezer algorithm mentioned in the original paper for multiple reasons.
See <span id="id6">[<a class="reference internal" href="#id34" title="Zengyou He, Xiaofei Xu, and Shengchun Deng. Discovering cluster-based local outliers. Pattern Recognition Letters, 24(9-10):1641–1650, 2003.">HXD03</a>]</span> for details.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_clusters</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=8</em><em>)</em>) – The number of clusters to form as well as the number of
centroids to generate.</p></li>
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</p></li>
<li><p><strong>clustering_estimator</strong> (<em>Estimator</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – The base clustering algorithm for performing data clustering.
A valid clustering algorithm should be passed in. The estimator should
have standard sklearn APIs, fit() and predict(). The estimator should
have attributes <code class="docutils literal notranslate"><span class="pre">labels_</span></code> and <code class="docutils literal notranslate"><span class="pre">cluster_centers_</span></code>.
If <code class="docutils literal notranslate"><span class="pre">cluster_centers_</span></code> is not in the attributes once the model is fit,
it is calculated as the mean of the samples in a cluster.
If not set, CBLOF uses KMeans for scalability. See
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html</a></p></li>
<li><p><strong>alpha</strong> (<em>float in</em><em> (</em><em>0.5</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.9</em><em>)</em>) – Coefficient for deciding small and large clusters. The ratio
of the number of samples in large clusters to the number of samples in
small clusters.</p></li>
<li><p><strong>beta</strong> (<em>int</em><em> or </em><em>float in</em><em> (</em><em>1</em><em>,</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=5</em><em>)</em><em>.</em>) – Coefficient for deciding small and large clusters. For a list
sorted clusters by size <cite>|C1|, |C2|, …, |Cn|, beta = |Ck|/|Ck-1|</cite></p></li>
<li><p><strong>use_weights</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If set to True, the size of clusters are used as weights in
outlier score calculation.</p></li>
<li><p><strong>check_estimator</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – <p>If set to True, check whether the base estimator is consistent with
sklearn standard.
.. warning:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">check_estimator</span> <span class="n">may</span> <span class="n">throw</span> <span class="n">errors</span> <span class="k">with</span> <span class="n">scikit</span><span class="o">-</span><span class="n">learn</span> <span class="mf">0.20</span> <span class="n">above</span><span class="o">.</span>
</pre></div>
</div>
</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <cite>np.random</cite>.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id107"><span class="problematic" id="id108">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</p>
</dd>
<dt><a href="#id109"><span class="problematic" id="id110">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id111"><span class="problematic" id="id112">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pyodcof">
<span id="tods-detection-algorithm-pyodcof"></span><h2>PyodCOF<a class="headerlink" href="#pyodcof" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PyodCOF.COFPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PyodCOF.</span></span><span class="sig-name descname"><span class="pre">COFPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PyodCOF.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PyodCOF.py#L70"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PyodCOF.COFPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Connectivity-Based Outlier Factor (COF) COF uses the ratio of average</dt><dd><p>chaining distance of data point and the average of average chaining
distance of k nearest neighbor of the data point, as the outlier score
for observations.
See <span id="id7">[<a class="reference internal" href="#id44" title="Jian Tang, Zhixiang Chen, Ada Wai-Chee Fu, and David W Cheung. Enhancing effectiveness of outlier detections for low density patterns. In Pacific-Asia Conference on Knowledge Discovery and Data Mining, 535–548. Springer, 2002.">TCFC02</a>]</span> for details.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</p></li>
<li><p><strong>n_neighbors</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=20</em><em>)</em>) – Number of neighbors to use by default for k neighbors queries.
Note that n_neighbors should be less than the number of samples.
If n_neighbors is larger than the number of samples provided,
all samples will be used.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id113"><span class="problematic" id="id114">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</p>
</dd>
<dt><a href="#id115"><span class="problematic" id="id116">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id117"><span class="problematic" id="id118">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
<dt><a href="#id119"><span class="problematic" id="id120">n_neighbors_</span></a>: int</dt><dd><p class="sd-card-text">Number of neighbors to use by default for k neighbors queries.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pyodhbos">
<span id="tods-detection-algorithm-pyodhbos"></span><h2>PyodHBOS<a class="headerlink" href="#pyodhbos" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PyodHBOS.HBOSPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PyodHBOS.</span></span><span class="sig-name descname"><span class="pre">HBOSPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PyodHBOS.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PyodHBOS.py#L76"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PyodHBOS.HBOSPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Histogram-based Outlier Detection (HBOS)</dt><dd><p>Histogram- based outlier detection (HBOS) is an efficient unsupervised
method. It assumes the feature independence and calculates the degree
of outlyingness by building histograms. See <span id="id8">[<a class="reference internal" href="#id27" title="Markus Goldstein and Andreas Dengel. Histogram-based outlier score (hbos): a fast unsupervised anomaly detection algorithm. KI-2012: Poster and Demo Track, pages 59–63, 2012.">GD12</a>]</span>
for details.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bins</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – The number of bins.</p></li>
<li><p><strong>alpha</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The regularizer for preventing overflow.</p></li>
<li><p><strong>tol</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The parameter to decide the flexibility while dealing
the samples falling outside the bins.</p></li>
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id121"><span class="problematic" id="id122">bin_edges_</span></a><span class="classifier">numpy array of shape (n_bins + 1, n_features )</span></dt><dd><p class="sd-card-text">The edges of the bins.</p>
</dd>
<dt><a href="#id123"><span class="problematic" id="id124">hist_</span></a><span class="classifier">numpy array of shape (n_bins, n_features)</span></dt><dd><p class="sd-card-text">The density of each histogram.</p>
</dd>
<dt><a href="#id125"><span class="problematic" id="id126">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is fitted.</p>
</dd>
<dt><a href="#id127"><span class="problematic" id="id128">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id129"><span class="problematic" id="id130">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pyodisolationforest">
<span id="tods-detection-algorithm-pyodisolationforest"></span><h2>PyodIsolationForest<a class="headerlink" href="#pyodisolationforest" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PyodIsolationForest.IsolationForestPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PyodIsolationForest.</span></span><span class="sig-name descname"><span class="pre">IsolationForestPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PyodIsolationForest.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PyodIsolationForest.py#L109"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PyodIsolationForest.IsolationForestPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Wrapper of Pyod Isolation Forest with more functionalities.</dt><dd><p>The IsolationForest ‘isolates’ observations by randomly selecting a
feature and then randomly selecting a split value between the maximum and
minimum values of the selected feature.
See <span id="id9">[<a class="reference internal" href="#id19" title="Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. Isolation forest. In Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on, 413–422. IEEE, 2008.">LTZ08</a>, <a class="reference internal" href="#id20" title="Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. Isolation-based anomaly detection. ACM Transactions on Knowledge Discovery from Data (TKDD), 6(1):3, 2012.">LTZ12</a>]</span> for details.
Since recursive partitioning can be represented by a tree structure, the
number of splittings required to isolate a sample is equivalent to the path
length from the root node to the terminating node.
This path length, averaged over a forest of such random trees, is a
measure of normality and our decision function.
Random partitioning produces noticeably shorter paths for anomalies.
Hence, when a forest of random trees collectively produce shorter path
lengths for particular samples, they are highly likely to be anomalies.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_estimators</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=100</em><em>)</em>) – The number of base estimators in the ensemble.</p></li>
<li><p><strong>max_samples</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;auto&quot;</em><em>)</em>) – <dl class="simple">
<dt>The number of samples to draw from X to train each base estimator.</dt><dd><ul>
<li><p>If int, then draw <cite>max_samples</cite> samples.</p></li>
<li><p>If float, then draw <cite>max_samples * X.shape[0]</cite> samples.</p></li>
<li><p>If “auto”, then <cite>max_samples=min(256, n_samples)</cite>.</p></li>
</ul>
</dd>
</dl>
<p>If max_samples is larger than the number of samples provided,
all samples will be used for all trees (no sampling).</p>
</p></li>
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e. the proportion
of outliers in the data set. Used when fitting to define the threshold
on the decision function.</p></li>
<li><p><strong>max_features</strong> (<em>int</em><em> or </em><em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1.0</em><em>)</em>) – <dl class="simple">
<dt>The number of features to draw from X to train each base estimator.</dt><dd><ul>
<li><p>If int, then draw <cite>max_features</cite> features.</p></li>
<li><p>If float, then draw <cite>max_features * X.shape[1]</cite> features.</p></li>
</ul>
</dd>
</dl>
</p></li>
<li><p><strong>bootstrap</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, individual trees are fit on random subsets of the training
data sampled with replacement. If False, sampling without replacement
is performed.</p></li>
<li><p><strong>behaviour</strong> (<em>str</em><em>, </em><em>default='old'</em>) – Behaviour of the <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> which can be either ‘old’ or
‘new’. Passing <code class="docutils literal notranslate"><span class="pre">behaviour='new'</span></code> makes the <code class="docutils literal notranslate"><span class="pre">decision_function</span></code>
change to match other anomaly detection algorithm API which will be
the default behaviour in the future. As explained in details in the
<code class="docutils literal notranslate"><span class="pre">offset_</span></code> attribute documentation, the <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> becomes
dependent on the contamination parameter, in such a way that 0 becomes
its natural threshold to detect outliers.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=0</em><em>)</em>) – Controls the verbosity of the tree building process.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id131"><span class="problematic" id="id132">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</p>
</dd>
<dt><a href="#id133"><span class="problematic" id="id134">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id135"><span class="problematic" id="id136">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pyodknn">
<span id="tods-detection-algorithm-pyodknn"></span><h2>PyodKNN<a class="headerlink" href="#pyodknn" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PyodKNN.KNNPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PyodKNN.</span></span><span class="sig-name descname"><span class="pre">KNNPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PyodKNN.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PyodKNN.py#L123"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PyodKNN.KNNPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>kNN class for outlier detection.</dt><dd><p>For an observation, its distance to its kth nearest neighbor could be
viewed as the outlying score. It could be viewed as a way to measure
the density. See <span id="id10">[<a class="reference internal" href="#id24" title="Fabrizio Angiulli and Clara Pizzuti. Fast outlier detection in high dimensional spaces. In European Conference on Principles of Data Mining and Knowledge Discovery, 15–27. Springer, 2002.">AP02</a>, <a class="reference internal" href="#id23" title="Sridhar Ramaswamy, Rajeev Rastogi, and Kyuseok Shim. Efficient algorithms for mining outliers from large data sets. In ACM Sigmod Record, volume 29, 427–438. ACM, 2000.">RRS00</a>]</span> for
details.
Three kNN detectors are supported:
largest: use the distance to the kth neighbor as the outlier score
mean: use the average of all k neighbors as the outlier score
median: use the median of the distance to k neighbors as the outlier score</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</p></li>
<li><p><strong>n_neighbors</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default = 5</em><em>)</em>) – Number of neighbors to use by default for k neighbors queries.</p></li>
<li><p><strong>method</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>default='largest'</em><em>)</em>) – <p>{‘largest’, ‘mean’, ‘median’}</p>
<ul>
<li><p>’largest’: use the distance to the kth neighbor as the outlier score</p></li>
<li><p>’mean’: use the average of all k neighbors as the outlier score</p></li>
<li><p>’median’: use the median of the distance to k neighbors as the
outlier score</p></li>
</ul>
</p></li>
<li><p><strong>radius</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default = 1.0</em><em>)</em>) – Range of parameter space to use by default for <cite>radius_neighbors</cite>
queries.</p></li>
<li><p><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>optional</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<ul>
<li><p>’ball_tree’ will use BallTree</p></li>
<li><p>’kd_tree’ will use KDTree</p></li>
<li><p>’brute’ will use a brute-force search.</p></li>
<li><p>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> method.</p></li>
</ul>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.
.. deprecated:: 0.74</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">algorithm</span></code> is deprecated in PyOD 0.7.4 and will not be
possible in 0.7.6. It has to use BallTree for consistency.</p>
</div></blockquote>
</p></li>
<li><p><strong>leaf_size</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default = 30</em><em>)</em>) – Leaf size passed to BallTree. This can affect the
speed of the construction and query, as well as the memory
required to store the tree.  The optimal value depends on the
nature of the problem.</p></li>
<li><p><strong>metric</strong> (<em>string</em><em> or </em><em>callable</em><em>, </em><em>default 'minkowski'</em>) – <p>metric to use for distance computation. Any metric from scikit-learn
or scipy.spatial.distance can be used.
If metric is a callable function, it is called on each
pair of instances (rows) and the resulting value recorded. The callable
should take two arrays as input and return one value indicating the
distance between them. This works for Scipy’s metrics, but is less
efficient than passing the metric name as a string.
Distance matrices are not supported.
Valid values for metric are:</p>
<ul>
<li><p>from scikit-learn: [‘cityblock’, ‘cosine’, ‘euclidean’, ‘l1’, ‘l2’,
‘manhattan’]</p></li>
<li><p>from scipy.spatial.distance: [‘braycurtis’, ‘canberra’, ‘chebyshev’,
‘correlation’, ‘dice’, ‘hamming’, ‘jaccard’, ‘kulsinski’,
‘mahalanobis’, ‘matching’, ‘minkowski’, ‘rogerstanimoto’,
‘russellrao’, ‘seuclidean’, ‘sokalmichener’, ‘sokalsneath’,
‘sqeuclidean’, ‘yule’]</p></li>
</ul>
<p>See the documentation for scipy.spatial.distance for details on these
metrics.</p>
</p></li>
<li><p><strong>p</strong> (<em>integer</em><em>, </em><em>optional</em><em> (</em><em>default = 2</em><em>)</em>) – Parameter for the Minkowski metric from
sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is
equivalent to using manhattan_distance (l1), and euclidean_distance
(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.
See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances">http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances</a></p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Additional keyword arguments for the metric function.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default = 1</em><em>)</em>) – The number of parallel jobs to run for neighbors search.
If <code class="docutils literal notranslate"><span class="pre">-1</span></code>, then the number of jobs is set to the number of CPU cores.
Affects only kneighbors and kneighbors_graph methods.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id137"><span class="problematic" id="id138">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</p>
</dd>
<dt><a href="#id139"><span class="problematic" id="id140">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id141"><span class="problematic" id="id142">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pyodloda">
<span id="tods-detection-algorithm-pyodloda"></span><h2>PyodLODA<a class="headerlink" href="#pyodloda" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PyodLODA.LODAPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PyodLODA.</span></span><span class="sig-name descname"><span class="pre">LODAPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PyodLODA.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PyodLODA.py#L69"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PyodLODA.LODAPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Wrap of Pyod loda. Loda: Lightweight on-line detector of anomalies. See</dt><dd><p><span id="id11">[<a class="reference internal" href="#id52" title="Tomáš Pevn\`y. Loda: lightweight on-line detector of anomalies. Machine Learning, 102(2):275–304, 2016.">Pevny16</a>]</span> for more information.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set,
i.e. the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</p></li>
<li><p><strong>n_bins</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default = 10</em><em>)</em>) – The number of bins for the histogram.</p></li>
<li><p><strong>n_random_cuts</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default = 100</em><em>)</em>) – The number of random cuts.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id143"><span class="problematic" id="id144">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</p>
</dd>
<dt><a href="#id145"><span class="problematic" id="id146">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id147"><span class="problematic" id="id148">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pyodlof">
<span id="tods-detection-algorithm-pyodlof"></span><h2>PyodLOF<a class="headerlink" href="#pyodlof" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PyodLOF.LOFPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PyodLOF.</span></span><span class="sig-name descname"><span class="pre">LOFPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PyodLOF.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PyodLOF.py#L110"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PyodLOF.LOFPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Wrapper of Pyod LOF Class with more functionalities.</dt><dd><p>Unsupervised Outlier Detection using Local Outlier Factor (LOF).
The anomaly score of each sample is called Local Outlier Factor.
It measures the local deviation of density of a given sample with
respect to its neighbors.
It is local in that the anomaly score depends on how isolated the object
is with respect to the surrounding neighborhood.
More precisely, locality is given by k-nearest neighbors, whose distance
is used to estimate the local density.
By comparing the local density of a sample to the local densities of
its neighbors, one can identify samples that have a substantially lower
density than their neighbors. These are considered outliers.
See <span id="id12">[<a class="reference internal" href="#id30" title="Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and Jörg Sander. Lof: identifying density-based local outliers. In ACM sigmod record, volume 29, 93–104. ACM, 2000.">BKNS00</a>]</span> for details.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_neighbors</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=20</em><em>)</em>) – Number of neighbors to use by default for <cite>kneighbors</cite> queries.
If n_neighbors is larger than the number of samples provided,
all samples will be used.</p></li>
<li><p><strong>algorithm</strong> (<em>{'auto'</em><em>, </em><em>'ball_tree'</em><em>, </em><em>'kd_tree'</em><em>, </em><em>'brute'}</em><em>, </em><em>optional</em>) – <p>Algorithm used to compute the nearest neighbors:</p>
<ul>
<li><p>’ball_tree’ will use BallTree</p></li>
<li><p>’kd_tree’ will use KDTree</p></li>
<li><p>’brute’ will use a brute-force search.</p></li>
<li><p>’auto’ will attempt to decide the most appropriate algorithm
based on the values passed to <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> method.</p></li>
</ul>
<p>Note: fitting on sparse input will override the setting of
this parameter, using brute force.</p>
</p></li>
<li><p><strong>leaf_size</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=30</em><em>)</em>) – Leaf size passed to <cite>BallTree</cite> or <cite>KDTree</cite>. This can
affect the speed of the construction and query, as well as the memory
required to store the tree. The optimal value depends on the
nature of the problem.</p></li>
<li><p><strong>metric</strong> (<em>string</em><em> or </em><em>callable</em><em>, </em><em>default 'minkowski'</em>) – <p>metric used for the distance computation. Any metric from scikit-learn
or scipy.spatial.distance can be used.
If ‘precomputed’, the training input X is expected to be a distance
matrix.
If metric is a callable function, it is called on each
pair of instances (rows) and the resulting value recorded. The callable
should take two arrays as input and return one value indicating the
distance between them. This works for Scipy’s metrics, but is less
efficient than passing the metric name as a string.
Valid values for metric are:</p>
<ul>
<li><p>from scikit-learn: [‘cityblock’, ‘cosine’, ‘euclidean’, ‘l1’, ‘l2’,
‘manhattan’]</p></li>
<li><p>from scipy.spatial.distance: [‘braycurtis’, ‘canberra’, ‘chebyshev’,
‘correlation’, ‘dice’, ‘hamming’, ‘jaccard’, ‘kulsinski’,
‘mahalanobis’, ‘matching’, ‘minkowski’, ‘rogerstanimoto’,
‘russellrao’, ‘seuclidean’, ‘sokalmichener’, ‘sokalsneath’,
‘sqeuclidean’, ‘yule’]</p></li>
</ul>
<p>See the documentation for scipy.spatial.distance for details on these
metrics:
<a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/spatial.distance.html">http://docs.scipy.org/doc/scipy/reference/spatial.distance.html</a></p>
</p></li>
<li><p><strong>p</strong> (<em>integer</em><em>, </em><em>optional</em><em> (</em><em>default = 2</em><em>)</em>) – Parameter for the Minkowski metric from
sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is
equivalent to using manhattan_distance (l1), and euclidean_distance
(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.
See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances">http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances</a></p></li>
<li><p><strong>metric_params</strong> (<em>dict</em><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Additional keyword arguments for the metric function.</p></li>
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e. the proportion
of outliers in the data set. When fitting this is used to define the
threshold on the decision function.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default = 1</em><em>)</em>) – The number of parallel jobs to run for neighbors search.
If <code class="docutils literal notranslate"><span class="pre">-1</span></code>, then the number of jobs is set to the number of CPU cores.
Affects only kneighbors and kneighbors_graph methods.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id149"><span class="problematic" id="id150">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</p>
</dd>
<dt><a href="#id151"><span class="problematic" id="id152">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id153"><span class="problematic" id="id154">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pyodmogaal">
<span id="tods-detection-algorithm-pyodmogaal"></span><h2>PyodMoGaal<a class="headerlink" href="#pyodmogaal" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PyodMoGaal.Mo_GaalPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PyodMoGaal.</span></span><span class="sig-name descname"><span class="pre">Mo_GaalPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PyodMoGaal.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PyodMoGaal.py#L125"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PyodMoGaal.Mo_GaalPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Multi-Objective Generative Adversarial Active Learning.</dt><dd><p>MO_GAAL directly generates informative potential outliers to assist the
classifier in describing a boundary that can separate outliers from normal
data effectively. Moreover, to prevent the generator from falling into the
mode collapsing problem, the network structure of SO-GAAL is expanded from
a single generator (SO-GAAL) to multiple generators with different
objectives (MO-GAAL) to generate a reasonable reference distribution for
the whole dataset.
Read more in the <span id="id13">[<a class="reference internal" href="#id39" title="Yezheng Liu, Zhe Li, Chong Zhou, Yuanchun Jiang, Jianshan Sun, Meng Wang, and Xiangnan He. Generative adversarial active learning for unsupervised outlier detection. IEEE Transactions on Knowledge and Data Engineering, 2019.">LLZ+19</a>]</span>.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</p></li>
<li><p><strong>k</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – The number of sub generators.</p></li>
<li><p><strong>stop_epochs</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=20</em><em>)</em>) – The number of epochs of training.</p></li>
<li><p><strong>lr_d</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.01</em><em>)</em>) – The learn rate of the discriminator.</p></li>
<li><p><strong>lr_g</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.0001</em><em>)</em>) – The learn rate of the generator.</p></li>
<li><p><strong>decay</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1e-6</em><em>)</em>) – The decay parameter for SGD.</p></li>
<li><p><strong>momentum</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.9</em><em>)</em>) – The momentum parameter for SGD.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id155"><span class="problematic" id="id156">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is fitted.</p>
</dd>
<dt><a href="#id157"><span class="problematic" id="id158">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id159"><span class="problematic" id="id160">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pyodocsvm">
<span id="tods-detection-algorithm-pyodocsvm"></span><h2>PyodOCSVM<a class="headerlink" href="#pyodocsvm" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PyodOCSVM.OCSVMPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PyodOCSVM.</span></span><span class="sig-name descname"><span class="pre">OCSVMPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PyodOCSVM.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PyodOCSVM.py#L128"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PyodOCSVM.OCSVMPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Wrapper of scikit-learn one-class SVM Class with more functionalities.</dt><dd><p>Unsupervised Outlier Detection.
Estimate the support of a high-dimensional distribution.
The implementation is based on libsvm.
See <a class="reference external" href="http://scikit-learn.org/stable/modules/svm.html#svm-outlier-detection">http://scikit-learn.org/stable/modules/svm.html#svm-outlier-detection</a>
and <span id="id14">[<a class="reference internal" href="#id43" title="Bernhard Schölkopf, John C Platt, John Shawe-Taylor, Alex J Smola, and Robert C Williamson. Estimating the support of a high-dimensional distribution. Neural computation, 13(7):1443–1471, 2001.">ScholkopfPST+01</a>]</span>.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='rbf'</em><em>)</em>) – Specifies the kernel type to be used in the algorithm.
It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or
a callable.
If none is given, ‘rbf’ will be used. If a callable is given it is
used to precompute the kernel matrix.</p></li>
<li><p><strong>nu</strong> (<em>float</em><em>, </em><em>optional</em>) – An upper bound on the fraction of training
errors and a lower bound of the fraction of support
vectors. Should be in the interval (0, 1]. By default 0.5
will be taken.</p></li>
<li><p><strong>degree</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=3</em><em>)</em>) – Degree of the polynomial kernel function (‘poly’).
Ignored by all other kernels.</p></li>
<li><p><strong>gamma</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default='auto'</em><em>)</em>) – Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.
If gamma is ‘auto’ then 1/n_features will be used instead.</p></li>
<li><p><strong>coef0</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.0</em><em>)</em>) – Independent term in kernel function.
It is only significant in ‘poly’ and ‘sigmoid’.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – Tolerance for stopping criterion.</p></li>
<li><p><strong>shrinking</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use the shrinking heuristic.</p></li>
<li><p><strong>cache_size</strong> (<em>float</em><em>, </em><em>optional</em>) – Specify the size of the kernel cache (in MB).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default: False</em>) – Enable verbose output. Note that this setting takes advantage of a
per-process runtime setting in libsvm that, if enabled, may not work
properly in a multithreaded context.</p></li>
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=-1</em><em>)</em>) – Hard limit on iterations within solver, or -1 for no limit.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id161"><span class="problematic" id="id162">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is fitted.</p>
</dd>
<dt><a href="#id163"><span class="problematic" id="id164">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id165"><span class="problematic" id="id166">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pyodsod">
<span id="tods-detection-algorithm-pyodsod"></span><h2>PyodSOD<a class="headerlink" href="#pyodsod" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PyodSOD.SODPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PyodSOD.</span></span><span class="sig-name descname"><span class="pre">SODPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PyodSOD.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PyodSOD.py#L74"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PyodSOD.SODPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Subspace outlier detection (SOD) schema aims to detect outlier in</dt><dd><p>varying subspaces of a high dimensional feature space. For each data
object, SOD explores the axis-parallel subspace spanned by the data
object’s neighbors and determines how much the object deviates from the
neighbors in this subspace.
See <span id="id15">[<a class="reference internal" href="#id46" title="Hans-Peter Kriegel, Peer Kröger, Erich Schubert, and Arthur Zimek. Outlier detection in axis-parallel subspaces of high dimensional data. In Pacific-Asia Conference on Knowledge Discovery and Data Mining, 831–838. Springer, 2009.">KKrogerSZ09</a>]</span> for details.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_neighbors</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=20</em><em>)</em>) – Number of neighbors to use by default for k neighbors queries.</p></li>
<li><p><strong>ref_set</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – specifies the number of shared nearest neighbors to create the
reference set. Note that ref_set must be smaller than n_neighbors.</p></li>
<li><p><strong>alpha</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>1.</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.8</em><em>)</em>) – specifies the lower limit for selecting subspace.
0.8 is set as default as suggested in the original paper.</p></li>
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id167"><span class="problematic" id="id168">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</p>
</dd>
<dt><a href="#id169"><span class="problematic" id="id170">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id171"><span class="problematic" id="id172">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pyodsogaal">
<span id="tods-detection-algorithm-pyodsogaal"></span><h2>PyodSoGaal<a class="headerlink" href="#pyodsogaal" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PyodSoGaal.So_GaalPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PyodSoGaal.</span></span><span class="sig-name descname"><span class="pre">So_GaalPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PyodSoGaal.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PyodSoGaal.py#L118"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PyodSoGaal.So_GaalPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Single-Objective Generative Adversarial Active Learning.</dt><dd><p>SO-GAAL directly generates informative potential outliers to assist the
classifier in describing a boundary that can separate outliers from normal
data effectively. Moreover, to prevent the generator from falling into the
mode collapsing problem, the network structure of SO-GAAL is expanded from
a single generator (SO-GAAL) to multiple generators with different
objectives (MO-GAAL) to generate a reasonable reference distribution for
the whole dataset.
Read more in the <span id="id16">[<a class="reference internal" href="#id39" title="Yezheng Liu, Zhe Li, Chong Zhou, Yuanchun Jiang, Jianshan Sun, Meng Wang, and Xiangnan He. Generative adversarial active learning for unsupervised outlier detection. IEEE Transactions on Knowledge and Data Engineering, 2019.">LLZ+19</a>]</span>.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. Used when fitting to
define the threshold on the decision function.</p></li>
<li><p><strong>stop_epochs</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=20</em><em>)</em>) – The number of epochs of training.</p></li>
<li><p><strong>lr_d</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.01</em><em>)</em>) – The learn rate of the discriminator.</p></li>
<li><p><strong>lr_g</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.0001</em><em>)</em>) – The learn rate of the generator.</p></li>
<li><p><strong>decay</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=1e-6</em><em>)</em>) – The decay parameter for SGD.</p></li>
<li><p><strong>momentum</strong> (<em>float</em><em>, </em><em>optional</em><em> (</em><em>default=0.9</em><em>)</em>) – The momentum parameter for SGD.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id173"><span class="problematic" id="id174">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is fitted.</p>
</dd>
<dt><a href="#id175"><span class="problematic" id="id176">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id177"><span class="problematic" id="id178">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="pyodvae">
<span id="tods-detection-algorithm-pyodvae"></span><h2>PyodVAE<a class="headerlink" href="#pyodvae" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.PyodVAE.VariationalAutoEncoderPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.PyodVAE.</span></span><span class="sig-name descname"><span class="pre">VariationalAutoEncoderPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.PyodVAE.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/PyodVAE.py#L189"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.PyodVAE.VariationalAutoEncoderPrimitive" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Auto Encoder (AE) is a type of neural networks for learning useful data</dt><dd><p>representations unsupervisedly. Similar to PCA, AE could be used to
detect outlying objects in the data by calculating the reconstruction
errors. See <span id="id17">[<a class="reference internal" href="#id29" title="Charu C Aggarwal. Outlier analysis. In Data mining, 75–79. Springer, 2015.">Agg15</a>]</span> Chapter 3 for details.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_neurons</strong> (<em>list</em><em>, </em><em>optional</em><em> (</em><em>default=</em><em>[</em><em>4</em><em>, </em><em>2</em><em>, </em><em>4</em><em>]</em><em>)</em>) – The number of neurons per hidden layers.</p></li>
<li><p><strong>hidden_activation</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>default='relu'</em><em>)</em>) – Activation function to use for hidden layers.
All hidden layers are forced to use the same type of activation.
See <a class="reference external" href="https://keras.io/activations/">https://keras.io/activations/</a></p></li>
<li><p><strong>output_activation</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>default='sigmoid'</em><em>)</em>) – Activation function to use for output layer.
See <a class="reference external" href="https://keras.io/activations/">https://keras.io/activations/</a></p></li>
<li><p><strong>loss</strong> (<em>str</em><em> or </em><em>obj</em><em>, </em><em>optional</em><em> (</em><em>default=keras.losses.mean_squared_error</em><em>)</em>) – String (name of objective function) or objective function.
See <a class="reference external" href="https://keras.io/losses/">https://keras.io/losses/</a></p></li>
<li><p><strong>optimizer</strong> (<em>str</em><em>, </em><em>optional</em><em> (</em><em>default='adam'</em><em>)</em>) – String (name of optimizer) or optimizer instance.
See <a class="reference external" href="https://keras.io/optimizers/">https://keras.io/optimizers/</a></p></li>
<li><p><strong>epochs</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=100</em><em>)</em>) – Number of epochs to train the model.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=32</em><em>)</em>) – Number of samples per gradient update.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.2</em><em>)</em>) – The dropout to be used across all layers.</p></li>
<li><p><strong>l2_regularizer</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The regularization strength of activity_regularizer
applied on each layer. By default, l2 regularizer is used. See
<a class="reference external" href="https://keras.io/regularizers/">https://keras.io/regularizers/</a></p></li>
<li><p><strong>validation_size</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>1</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The percentage of data to be used for validation.</p></li>
<li><p><strong>preprocessing</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, apply standardization on the data.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – Verbosity mode.
- 0 = silent
- 1 = progress bar
- 2 = one line per epoch.
For verbosity &gt;= 1, model summary may be printed.</p></li>
<li><p><strong>random_state</strong> (<em>random_state: int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – (default=None)
If int, random_state is the seed used by the random
number generator; If RandomState instance, random_state is the random
number generator; If None, the random number generator is the
RandomState instance used by <cite>np.random</cite>.</p></li>
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e.
the proportion of outliers in the data set. When fitting this is used
to define the threshold on the decision function.</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Attributes<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt><a href="#id179"><span class="problematic" id="id180">encoding_dim_</span></a><span class="classifier">int</span></dt><dd><p class="sd-card-text">The number of neurons in the encoding layer.</p>
</dd>
<dt><a href="#id181"><span class="problematic" id="id182">compression_rate_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The ratio between the original feature and
the number of neurons in the encoding layer.</p>
</dd>
<dt><a href="#id183"><span class="problematic" id="id184">model_</span></a><span class="classifier">Keras Object</span></dt><dd><p class="sd-card-text">The underlying AutoEncoder in Keras.</p>
</dd>
<dt><a href="#id185"><span class="problematic" id="id186">history_</span></a>: Keras Object</dt><dd><p class="sd-card-text">The AutoEncoder training history.</p>
</dd>
<dt><a href="#id187"><span class="problematic" id="id188">decision_scores_</span></a><span class="classifier">numpy array of shape (n_samples,)</span></dt><dd><p class="sd-card-text">The outlier scores of the training data.
The higher, the more abnormal. Outliers tend to have higher
scores. This value is available once the detector is
fitted.</p>
</dd>
<dt><a href="#id189"><span class="problematic" id="id190">threshold_</span></a><span class="classifier">float</span></dt><dd><p class="sd-card-text">The threshold is based on <code class="docutils literal notranslate"><span class="pre">contamination</span></code>. It is the
<code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">*</span> <span class="pre">contamination</span></code> most abnormal samples in
<code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>. The threshold is calculated for generating
binary outlier labels.</p>
</dd>
<dt><a href="#id191"><span class="problematic" id="id192">labels_</span></a><span class="classifier">int, either 0 or 1</span></dt><dd><p class="sd-card-text">The binary labels of the training data. 0 stands for inliers
and 1 for outliers/anomalies. It is generated by applying
<code class="docutils literal notranslate"><span class="pre">threshold_</span></code> on <code class="docutils literal notranslate"><span class="pre">decision_scores_</span></code>.</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="systemwisedetection">
<span id="tods-detection-algorithm-systemwisedetection"></span><h2>SystemWiseDetection<a class="headerlink" href="#systemwisedetection" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.SystemWiseDetection.SystemWiseDetectionPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.SystemWiseDetection.</span></span><span class="sig-name descname"><span class="pre">SystemWiseDetectionPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.SystemWiseDetection.Hyperparams</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/SystemWiseDetection.py#L105"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.SystemWiseDetection.SystemWiseDetectionPrimitive" title="Permalink to this definition">#</a></dt>
<dd><p>Primitive to find abs_energy of time series.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>window_size</strong> (<em>int</em><em>(</em><em>default=10</em><em>)</em>) – Window Size for decomposition</p></li>
<li><p><strong>method_type</strong> (<em>str</em><em> (</em><em>'max'</em><em>, </em><em>'avg'</em><em>, </em><em>'sliding_window_sum'</em><em>,</em><em>'majority_voting_sliding_window_sum'</em><em>,</em><em>'majority_voting_sliding_window_max'</em><em>)</em>) – The type of method used to find anomalous system</p></li>
<li><p><strong>contamination</strong> (<em>float in</em><em> (</em><em>0.</em><em>, </em><em>0.5</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – The amount of contamination of the data set, i.e. the proportion of outliers in the data set.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="telemanom">
<span id="tods-detection-algorithm-telemanom"></span><h2>Telemanom<a class="headerlink" href="#telemanom" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.Telemanom.TelemanomPrimitive">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.Telemanom.</span></span><span class="sig-name descname"><span class="pre">TelemanomPrimitive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tods.detection_algorithm.Telemanom.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/Telemanom.py#L189"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.Telemanom.TelemanomPrimitive" title="Permalink to this definition">#</a></dt>
<dd><p>A primitive that uses telmanom for outlier detection</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>smoothing_perc</strong> (<em>float</em><em> (</em><em>default=0.05</em><em>)</em>) – determines window size used in EWMA smoothing (percentage of total values for channel)</p></li>
<li><p><strong>window_size</strong> (<em>int</em><em>(</em><em>default=100</em><em>)</em>) – number of trailing batches to use in error calculation</p></li>
<li><p><strong>error_buffer</strong> (<em>int</em><em>(</em><em>default=50</em><em>)</em>) – number of values surrounding an error that are brought into the sequence (promotes grouping on nearby sequences</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>(</em><em>default=70</em><em>)</em>) – Batch size while predicting</p></li>
</ul>
</dd>
</dl>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
LSTM Model Parameters<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt>dropout :float(default=0.3)</dt><dd><p class="sd-card-text">Dropout rate</p>
</dd>
<dt>validation_split :float(default=0.2)</dt><dd><p class="sd-card-text">Validation split</p>
</dd>
<dt>optimizer :(default=’Adam’)</dt><dd><p class="sd-card-text">Optimizer</p>
</dd>
<dt>lstm_batch_size :int (default=64)</dt><dd><p class="sd-card-text">lstm model training batch size</p>
</dd>
<dt>loss_metric :(default=’mean_squared_error’)</dt><dd><p class="sd-card-text">loss function</p>
</dd>
<dt>layers = List(default=[10,10])</dt><dd><p class="sd-card-text">No of units for the 2 lstm layers</p>
</dd>
</dl>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Training Parameters<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt>epochs :int(default=1)</dt><dd><p class="sd-card-text">Epoch</p>
</dd>
<dt>patience  :int(default=10)</dt><dd><p class="sd-card-text">Number of consequetive training iterations to allow without decreasing the val_loss by at least min_delta</p>
</dd>
<dt>min_delta :float(default=0.0003)</dt><dd><p class="sd-card-text">Number of consequetive training iterations to allow without decreasing the val_loss by at least min_delta</p>
</dd>
<dt>l_s :int(default=100)</dt><dd><p class="sd-card-text">num previous timesteps provided to model to predict future values</p>
</dd>
<dt>n_predictions :int(default=10)</dt><dd><p class="sd-card-text">number of steps ahead to predict</p>
</dd>
</dl>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Error thresholding parameters<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt>p :float(default=0.05)</dt><dd><p class="sd-card-text">minimum percent decrease between max errors in anomalous sequences (used for pruning)</p>
</dd>
</dl>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Contamination<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<dl class="simple">
<dt>contamination<span class="classifier">float in (0., 0.5), optional (default=0.1)</span></dt><dd><p class="sd-card-text">the amount of contamination of the data set, i.e.the proportion of outliers in the data set. Used when fitting to define the threshold on the decision function</p>
</dd>
</dl>
</div>
</details></dd></dl>

</section>
<section id="uodbaseprimitive">
<span id="tods-detection-algorithm-uodbaseprimitive"></span><h2>UODBasePrimitive<a class="headerlink" href="#uodbaseprimitive" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tods.detection_algorithm.UODBasePrimitive.UnsupervisedOutlierDetectorBase">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tods.detection_algorithm.UODBasePrimitive.</span></span><span class="sig-name descname"><span class="pre">UnsupervisedOutlierDetectorBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">d3m.primitive_interfaces.base.Hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">docker_containers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">d3m.primitive_interfaces.base.DockerContainer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/datamllab/tods/blob/master/tods/detection_algorithm/UODBasePrimitive.py#L148"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tods.detection_algorithm.UODBasePrimitive.UnsupervisedOutlierDetectorBase" title="Permalink to this definition">#</a></dt>
<dd><p>A base class for primitives which have to be fitted before they can start
producing (useful) outputs from inputs, but they are fitted only on input data.</p>
</dd></dl>

</section>
<section id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">#</a></h2>
<div class="docutils container" id="id18">
<dl class="citation">
<dt class="label" id="id29"><span class="brackets">Agg15</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id3">2</a>,<a href="#id5">3</a>,<a href="#id17">4</a>)</span></dt>
<dd><p>Charu C Aggarwal. Outlier analysis. In <em>Data mining</em>, 75–79. Springer, 2015.</p>
</dd>
<dt class="label" id="id24"><span class="brackets">AP02</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id10">2</a>)</span></dt>
<dd><p>Fabrizio Angiulli and Clara Pizzuti. Fast outlier detection in high dimensional spaces. In <em>European Conference on Principles of Data Mining and Knowledge Discovery</em>, 15–27. Springer, 2002.</p>
</dd>
<dt class="label" id="id30"><span class="brackets"><a class="fn-backref" href="#id12">BKNS00</a></span></dt>
<dd><p>Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and Jörg Sander. Lof: identifying density-based local outliers. In <em>ACM sigmod record</em>, volume 29, 93–104. ACM, 2000.</p>
</dd>
<dt class="label" id="id27"><span class="brackets"><a class="fn-backref" href="#id8">GD12</a></span></dt>
<dd><p>Markus Goldstein and Andreas Dengel. Histogram-based outlier score (hbos): a fast unsupervised anomaly detection algorithm. <em>KI-2012: Poster and Demo Track</em>, pages 59–63, 2012.</p>
</dd>
<dt class="label" id="id34"><span class="brackets"><a class="fn-backref" href="#id6">HXD03</a></span></dt>
<dd><p>Zengyou He, Xiaofei Xu, and Shengchun Deng. Discovering cluster-based local outliers. <em>Pattern Recognition Letters</em>, 24(9-10):1641–1650, 2003.</p>
</dd>
<dt class="label" id="id46"><span class="brackets"><a class="fn-backref" href="#id15">KKrogerSZ09</a></span></dt>
<dd><p>Hans-Peter Kriegel, Peer Kröger, Erich Schubert, and Arthur Zimek. Outlier detection in axis-parallel subspaces of high dimensional data. In <em>Pacific-Asia Conference on Knowledge Discovery and Data Mining</em>, 831–838. Springer, 2009.</p>
</dd>
<dt class="label" id="id25"><span class="brackets"><a class="fn-backref" href="#id4">KZ+08</a></span></dt>
<dd><p>Hans-Peter Kriegel, Arthur Zimek, and others. Angle-based outlier detection in high-dimensional data. In <em>Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</em>, 444–452. ACM, 2008.</p>
</dd>
<dt class="label" id="id19"><span class="brackets"><a class="fn-backref" href="#id9">LTZ08</a></span></dt>
<dd><p>Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. Isolation forest. In <em>Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on</em>, 413–422. IEEE, 2008.</p>
</dd>
<dt class="label" id="id20"><span class="brackets"><a class="fn-backref" href="#id9">LTZ12</a></span></dt>
<dd><p>Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. Isolation-based anomaly detection. <em>ACM Transactions on Knowledge Discovery from Data (TKDD)</em>, 6(1):3, 2012.</p>
</dd>
<dt class="label" id="id39"><span class="brackets">LLZ+19</span><span class="fn-backref">(<a href="#id13">1</a>,<a href="#id16">2</a>)</span></dt>
<dd><p>Yezheng Liu, Zhe Li, Chong Zhou, Yuanchun Jiang, Jianshan Sun, Meng Wang, and Xiangnan He. Generative adversarial active learning for unsupervised outlier detection. <em>IEEE Transactions on Knowledge and Data Engineering</em>, 2019.</p>
</dd>
<dt class="label" id="id52"><span class="brackets"><a class="fn-backref" href="#id11">Pevny16</a></span></dt>
<dd><p>Tomáš Pevn\`y. Loda: lightweight on-line detector of anomalies. <em>Machine Learning</em>, 102(2):275–304, 2016.</p>
</dd>
<dt class="label" id="id23"><span class="brackets">RRS00</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id10">2</a>)</span></dt>
<dd><p>Sridhar Ramaswamy, Rajeev Rastogi, and Kyuseok Shim. Efficient algorithms for mining outliers from large data sets. In <em>ACM Sigmod Record</em>, volume 29, 427–438. ACM, 2000.</p>
</dd>
<dt class="label" id="id43"><span class="brackets"><a class="fn-backref" href="#id14">ScholkopfPST+01</a></span></dt>
<dd><p>Bernhard Schölkopf, John C Platt, John Shawe-Taylor, Alex J Smola, and Robert C Williamson. Estimating the support of a high-dimensional distribution. <em>Neural computation</em>, 13(7):1443–1471, 2001.</p>
</dd>
<dt class="label" id="id44"><span class="brackets"><a class="fn-backref" href="#id7">TCFC02</a></span></dt>
<dd><p>Jian Tang, Zhixiang Chen, Ada Wai-Chee Fu, and David W Cheung. Enhancing effectiveness of outlier detections for low density patterns. In <em>Pacific-Asia Conference on Knowledge Discovery and Data Mining</em>, 535–548. Springer, 2002.</p>
</dd>
</dl>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="tods.feature_analysis.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">tods.feature_analysis</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="tods.reinforcement.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">tods.reinforcement</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By DataLab@Rice University<br/>
  
      &copy; Copyright 2022, DataLab@Rice University.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>